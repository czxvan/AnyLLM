model: Qwen/Qwen3-0.6B
host: "127.0.0.1"
port: 8000
max-model-len: 4096
max-num-seqs: 2
gpu-memory-utilization: 0.6
uvicorn-log-level: "info"

# CUDA_VISIBLE_DEVICES=2 VLLM_USE_MODELSCOPE=true vllm serve --config config/vllm-Qwen3-0.6B.yaml 