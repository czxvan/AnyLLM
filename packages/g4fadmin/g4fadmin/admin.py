"""
G4FAdmin - GPT4Free Provider Management Tool

Core Classes:
  - G4FAdmin: Main management class
  - ProviderInfo: Provider information dataclass  
  - ModelInfo: Model information dataclass
  - TestResult: Test result dataclass
  - AuthType: Authentication type enum

Main Features:
  1. Provider management: scan, filter, recommend providers
  2. Model management: get all models and their supporting providers
  3. Authentication detection: identify auth methods through testing
  4. Real testing: test provider/model combination availability
  5. Batch testing: concurrent testing of multiple combinations
  6. Data export: export to JSON format

Usage Example:
    >>> admin = G4FAdmin()
    >>> providers = admin.get_recommended_providers(5)
    >>> success, resp, time = admin.test_provider("ApiAirforce", "gpt-4")
"""

import logging
import time
import json
from typing import List, Dict, Optional, Set, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from enum import Enum
import concurrent.futures

logger = logging.getLogger(__name__)


class AuthType(Enum):
    """Authentication type"""
    NONE = "none"
    API_KEY = "api_key"
    COOKIE = "cookie"
    TOKEN = "token"
    HAR_FILE = "har_file"
    ACCOUNT = "account"
    UNKNOWN = "unknown"


@dataclass
class ProviderInfo:
    """Provider information"""
    name: str
    working: bool
    supports_stream: bool
    supports_message_history: bool
    supports_system_message: bool
    models: List[str]
    auth_type: AuthType = AuthType.NONE
    auth_required: bool = False
    
    def to_dict(self) -> dict:
        return {
            'name': self.name,
            'working': self.working,
            'supports_stream': self.supports_stream,
            'supports_message_history': self.supports_message_history,
            'supports_system_message': self.supports_system_message,
            'models': self.models,
            'auth_type': self.auth_type.value,
            'auth_required': self.auth_required,
        }


@dataclass
class ModelInfo:
    """Model information"""
    name: str
    providers: List[str]
    
    def to_dict(self) -> dict:
        return {'name': self.name, 'providers': self.providers}


@dataclass
class TestResult:
    """Test result"""
    provider: str
    model: str
    success: bool
    response: Optional[str] = None
    response_time: Optional[float] = None
    auth_type: AuthType = AuthType.NONE
    timestamp: datetime = field(default_factory=datetime.now)
    
    def to_dict(self) -> dict:
        return {
            'provider': self.provider,
            'model': self.model,
            'success': self.success,
            'response': self.response,
            'response_time': self.response_time,
            'auth_type': self.auth_type.value,
            'timestamp': self.timestamp.isoformat(),
        }


class G4FAdmin:
    """G4F Providerç®¡ç†å·¥å…·"""
    
    # é»˜è®¤é»‘åå•
    DEFAULT_BLACKLIST = {
        "Copilot", "CopilotAccount", "OpenaiAccount", "OpenaiChat",
        "GithubCopilot", "LMArena", "Gemini", "AnyProvider"
    }
    
    # è®¤è¯å…³é”®è¯
    AUTH_KEYWORDS = {
        AuthType.API_KEY: ["api key", "api_key", "apikey"],
        AuthType.COOKIE: ["cookie", "__secure", "session"],
        AuthType.TOKEN: ["token", "bearer", "authorization"],
        AuthType.HAR_FILE: [".har", "har file", "browser_cookie"],
        AuthType.ACCOUNT: ["login", "account", "credentials"],
    }
    
    def __init__(self, blacklist: Optional[Set[str]] = None):
        """åˆå§‹åŒ–"""
        try:
            import g4f
            self.g4f = g4f
        except ImportError:
            raise ImportError("è¯·å®‰è£…g4f: pip install -U g4f")
        
        self._blacklist = blacklist or self.DEFAULT_BLACKLIST
        self._providers_cache: Optional[List[ProviderInfo]] = None
        self._models_cache: Optional[List[ModelInfo]] = None
        self._last_scan_time: Optional[datetime] = None
    
    def get_all_providers(self, force_refresh: bool = False) -> List[ProviderInfo]:
        """è·å–æ‰€æœ‰provider"""
        if self._providers_cache and not force_refresh:
            return self._providers_cache
        
        providers = []
        for provider in self.g4f.Provider.__providers__:
            try:
                name = getattr(provider, '__name__', str(provider))
                if name in self._blacklist:
                    continue
                
                models = self._extract_models(provider)
                needs_auth = getattr(provider, 'needs_auth', False)
                
                info = ProviderInfo(
                    name=name,
                    working=getattr(provider, 'working', False),
                    supports_stream=getattr(provider, 'supports_stream', False),
                    supports_message_history=getattr(provider, 'supports_message_history', True),
                    supports_system_message=getattr(provider, 'supports_system_message', True),
                    models=models,
                    auth_type=AuthType.UNKNOWN if needs_auth else AuthType.NONE,
                    auth_required=needs_auth,
                )
                providers.append(info)
            except Exception as e:
                logger.warning(f"æ— æ³•è·å–provider {provider}: {e}")
        
        self._providers_cache = providers
        self._last_scan_time = datetime.now()
        return providers
    
    def _extract_models(self, provider) -> List[str]:
        """æå–æ–‡æœ¬æ¨¡å‹åˆ—è¡¨"""
        models = []
        
        # 1. é¦–å…ˆæ£€æŸ¥modelså±æ€§
        if hasattr(provider, 'models'):
            attr = provider.models
            if isinstance(attr, list):
                models = [m for m in attr if isinstance(m, str)]
            elif isinstance(attr, dict):
                models = [k for k in attr.keys() if isinstance(k, str)]
        
        # 2. æ£€æŸ¥model_aliasesï¼Œæå–åˆ«åï¼ˆkeysï¼‰å’ŒçœŸå®æ¨¡å‹åï¼ˆvaluesï¼‰
        if hasattr(provider, 'model_aliases'):
            aliases = provider.model_aliases
            if isinstance(aliases, dict):
                # æå–åˆ«åï¼ˆç”¨æˆ·å¯ä»¥ä½¿ç”¨çš„ç®€çŸ­åç§°ï¼‰
                alias_keys = [k for k in aliases.keys() if isinstance(k, str)]
                
                # æå–çœŸå®æ¨¡å‹å
                alias_values = []
                for value in aliases.values():
                    if isinstance(value, str):
                        alias_values.append(value)
                    elif isinstance(value, list):
                        alias_values.extend([v for v in value if isinstance(v, str)])
                
                # å¦‚æœåŸæœ¬æ²¡æœ‰modelsï¼Œä½¿ç”¨åˆ«åï¼ˆæ›´ç®€çŸ­æ˜“ç”¨ï¼‰
                if not models:
                    models = alias_keys
                # å¦åˆ™è¡¥å……åˆ«ååˆ°ç°æœ‰models
                else:
                    models.extend(alias_keys)
                    models = list(set(models))  # å»é‡
        
        # 3. å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œæ£€æŸ¥default_model
        if not models and hasattr(provider, 'default_model'):
            default = provider.default_model
            if default and isinstance(default, str):
                models = [default]
        
        return models
    
    def get_working_providers(
        self, 
        require_stream: bool = False,
        require_auth: Optional[bool] = None
    ) -> List[ProviderInfo]:
        """è·å–å¯ç”¨provider"""
        providers = [p for p in self.get_all_providers() if p.working]
        if require_stream:
            providers = [p for p in providers if p.supports_stream]
        if require_auth is not None:
            providers = [p for p in providers if p.auth_required == require_auth]
        return providers
    
    def get_recommended_providers(self, top_n: int = 5) -> List[ProviderInfo]:
        """æ¨èprovider (ä¼˜å…ˆå·²çŸ¥ç¨³å®šçš„ã€æ— è®¤è¯ã€æ”¯æŒå†å²ã€æµå¼ã€æ¨¡å‹å¤š)"""
        candidates = self.get_working_providers(require_auth=False)
        
        # è¿‡æ»¤æ‰å¯èƒ½æ˜¯éŸ³é¢‘/å›¾åƒæ¨¡å‹çš„provider
        audio_image_keywords = ['audio', 'fm', 'image', 'flux', 'dalle', 'midjourney', 'blackforest']
        candidates = [
            p for p in candidates 
            if not any(kw in p.name.lower() for kw in audio_image_keywords)
        ]
        
        # åŠ è½½å·²çŸ¥ç¨³å®šproviders
        try:
            from .config import KNOWN_STABLE_PROVIDERS
            known_stable = set(KNOWN_STABLE_PROVIDERS)
        except ImportError:
            known_stable = set()
        
        def score(p: ProviderInfo) -> int:
            # ä¼˜å…ˆçº§ï¼šå·²çŸ¥ç¨³å®š > æ”¯æŒå†å² > æµå¼ > ç³»ç»Ÿæ¶ˆæ¯ > æ¨¡å‹æ•°é‡
            s = 0
            if p.name in known_stable:
                s += 1000  # å·²çŸ¥ç¨³å®šçš„ä¼˜å…ˆçº§æœ€é«˜
            if p.supports_message_history:
                s += 100
            if p.supports_stream:
                s += 50
            if p.supports_system_message:
                s += 20
            s += min(len(p.models), 50)  # æ¨¡å‹æ•°é‡ï¼Œä½†ä¸è¶…è¿‡50
            return s
        
        return sorted(candidates, key=score, reverse=True)[:top_n]
    
    def get_all_models(self, force_refresh: bool = False) -> List[ModelInfo]:
        """è·å–æ‰€æœ‰æ¨¡å‹"""
        if self._models_cache and not force_refresh:
            return self._models_cache
        
        model_providers: Dict[str, Set[str]] = {}
        for p in self.get_all_providers(force_refresh):
            if not p.working:
                continue
            for model in p.models:
                model_providers.setdefault(model, set()).add(p.name)
        
        models = [
            ModelInfo(name=m, providers=sorted(ps))
            for m, ps in sorted(model_providers.items())
        ]
        self._models_cache = models
        return models
    
    def find_providers_for_model(self, model_name: str) -> List[str]:
        """æŸ¥æ‰¾æ”¯æŒæŒ‡å®šæ¨¡å‹çš„provider"""
        model_lower = model_name.lower()
        providers = []
        for p in self.get_all_providers():
            if not p.working:
                continue
            for m in p.models:
                if model_lower in m.lower() or m.lower() in model_lower:
                    providers.append(p.name)
                    break
        return providers
    
    def _identify_auth_from_error(self, error_msg: str) -> AuthType:
        """ä»é”™è¯¯ä¿¡æ¯è¯†åˆ«Authentication type"""
        error_lower = error_msg.lower()
        for auth_type, keywords in self.AUTH_KEYWORDS.items():
            if any(kw in error_lower for kw in keywords):
                return auth_type
        if any(w in error_lower for w in ["auth", "unauthor", "forbidden", "403"]):
            return AuthType.UNKNOWN
        return AuthType.NONE
    
    def _extract_text_from_response(self, response) -> str:
        """æå–å“åº”æ–‡æœ¬"""
        try:
            from json_repair import repair_json
            has_repair = True
        except ImportError:
            has_repair = False
        
        # å­—ç¬¦ä¸²
        if isinstance(response, str):
            if has_repair:
                try:
                    response = json.loads(repair_json(response))
                except:
                    return response.strip()
            else:
                return response.strip()
        
        # å­—å…¸
        if isinstance(response, dict):
            # é”™è¯¯å“åº”
            if 'error_code' in response or response.get('status') == 'failed':
                return f"[é”™è¯¯] {response.get('text', response.get('error_code', 'æœªçŸ¥'))}"
            
            # æ ‡å‡†æ ¼å¼
            if 'choices' in response and response['choices']:
                choice = response['choices'][0]
                if isinstance(choice, dict):
                    if 'message' in choice:
                        return choice['message'].get('content', '').strip()
                    if 'text' in choice:
                        return choice['text'].strip()
            
            # å…¶ä»–æ ¼å¼
            for key in ['text', 'content', 'answer', 'message']:
                if key in response and response[key]:
                    return str(response[key]).strip()
            
            return f"[æœªè§£æ] {str(response)[:100]}..."
        
        # ç”Ÿæˆå™¨
        if hasattr(response, '__iter__') and not isinstance(response, (str, dict)):
            try:
                chunks = [str(c).strip() for c in response if str(c).strip() and str(c) != '{}']
                return ''.join(chunks).strip()
            except:
                pass
        
        return str(response).strip()
    
    def test_provider(
        self,
        provider_name: str,
        model_name: Optional[str] = None,
        test_prompt: str = "Hello",
        timeout: int = 15,
        verbose: bool = False
    ) -> Tuple[bool, Optional[str], Optional[float]]:
        """æµ‹è¯•provider"""
        try:
            if not hasattr(self.g4f.Provider, provider_name):
                return False, f"Provider {provider_name} ä¸å­˜åœ¨", None
            
            provider = getattr(self.g4f.Provider, provider_name)
            
            # BlackboxProç‰¹æ®Šå¤„ç†ï¼šåªæ¥å—ç©ºå­—ç¬¦ä¸²ä½œä¸ºmodel
            # å®ƒçš„modelsåˆ—è¡¨åŒ…å«å¾ˆå¤šæ¨¡å‹åï¼Œä½†å®é™…APIåªæ¥å—ç©ºå­—ç¬¦ä¸²
            if provider_name == 'BlackboxPro':
                model_name = ''  # å¼ºåˆ¶ä½¿ç”¨ç©ºå­—ç¬¦ä¸²
            
            # è‡ªåŠ¨é€‰æ‹©æ¨¡å‹
            if model_name is None:
                if hasattr(provider, 'default_model'):
                    model_name = provider.default_model
                elif hasattr(provider, 'models') and provider.models:
                    models = provider.models
                    if isinstance(models, list):
                        # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
                        valid_models = [m for m in models if m]
                        model_name = valid_models[0] if valid_models else 'auto'
                    else:
                        model_name = 'auto'
                else:
                    model_name = 'auto'
            
            start_time = time.time()
            response = self.g4f.ChatCompletion.create(
                model=model_name,
                messages=[{"role": "user", "content": test_prompt}],
                provider=provider,
                timeout=timeout,
            )
            
            # å¤„ç†ç”Ÿæˆå™¨
            if hasattr(response, '__iter__') and not isinstance(response, (str, dict)):
                chunks = list(response)
                response = chunks[-1] if chunks and isinstance(chunks[-1], dict) else ''.join(str(c) for c in chunks if str(c).strip() and str(c) != '{}')
            
            # å¦‚æœresponseæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•ç”¨repair_jsonä¿®è¡¥ä¸ºJSON
            if isinstance(response, str):
                try:
                    from json_repair import repair_json
                    response = json.loads(repair_json(response))
                except ImportError:
                    pass  # æ²¡æœ‰å®‰è£…json_repairï¼Œä¿æŒå­—ç¬¦ä¸²
                except Exception:
                    pass  # ä¿®è¡¥å¤±è´¥ï¼Œä¿æŒåŸå­—ç¬¦ä¸²
            
            resp_time = time.time() - start_time
            text = self._extract_text_from_response(response)
            
            if not text:
                return False, "å“åº”ä¸ºç©º", resp_time
            if text.startswith("[é”™è¯¯]"):
                return False, text, resp_time
            
            # æˆªæ–­
            if len(text) > 200:
                text = text[:200] + "..."
            
            return True, text, resp_time
        
        except Exception as e:
            error_msg = str(e)
            auth_type = self._identify_auth_from_error(error_msg)
            if auth_type != AuthType.NONE:
                return False, f"[{auth_type.value}] {error_msg}", None
            return False, error_msg, None
    
    def batch_test_providers(
        self,
        provider_names: Optional[List[str]] = None,
        test_prompt: str = "1+1=?",
        timeout: int = 15
    ) -> Dict[str, Tuple[bool, Optional[str], Optional[float]]]:
        """æ‰¹é‡æµ‹è¯•provider"""
        if provider_names is None:
            provider_names = [p.name for p in self.get_recommended_providers(10)]
        
        results = {}
        for i, name in enumerate(provider_names):
            results[name] = self.test_provider(name, test_prompt=test_prompt, timeout=timeout)
            if i < len(provider_names) - 1:
                time.sleep(0.5)
        
        return results
    
    def test_all_combinations(
        self,
        test_prompt: str = "ä½ å¥½",
        timeout: int = 15,
        max_workers: int = 8
    ) -> List[TestResult]:
        """å¹¶å‘æµ‹è¯•æ‰€æœ‰ç»„åˆ"""
        try:
            from tqdm import tqdm
            use_tqdm = True
        except ImportError:
            use_tqdm = False
        
        providers = self.get_working_providers()
        tasks = [(p.name, m) for p in providers for m in p.models]
        results = []
        
        def test_one(prov: str, mod: str) -> Optional[TestResult]:
            success, resp, t = self.test_provider(prov, mod, test_prompt, timeout, False)
            if success or resp:
                auth = AuthType.NONE
                if not success and resp:
                    auth = self._identify_auth_from_error(resp)
                return TestResult(prov, mod, success, resp, t, auth)
            return None
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(test_one, p, m): (p, m) for p, m in tasks}
            
            if use_tqdm:
                with tqdm(total=len(futures), desc="æµ‹è¯•ç»„åˆ", unit="é¡¹") as pbar:
                    for future in concurrent.futures.as_completed(futures):
                        if r := future.result():
                            results.append(r)
                        pbar.update(1)
            else:
                for future in concurrent.futures.as_completed(futures):
                    if r := future.result():
                        results.append(r)
        
        return results
    
    def export_providers(self, filepath: str):
        """å¯¼å‡ºproviderä¿¡æ¯"""
        providers = self.get_all_providers()
        data = {
            'scan_time': self._last_scan_time.isoformat() if self._last_scan_time else None,
            'total': len(providers),
            'working': sum(1 for p in providers if p.working),
            'providers': [p.to_dict() for p in providers]
        }
        Path(filepath).parent.mkdir(parents=True, exist_ok=True)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def export_models(self, filepath: str):
        """å¯¼å‡ºmodelä¿¡æ¯"""
        models = self.get_all_models()
        data = {
            'scan_time': self._last_scan_time.isoformat() if self._last_scan_time else None,
            'total': len(models),
            'models': [m.to_dict() for m in models]
        }
        Path(filepath).parent.mkdir(parents=True, exist_ok=True)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def export_test_results(self, results: List[TestResult], filepath: str):
        """å¯¼å‡ºTest result"""
        data = {
            'test_time': datetime.now().isoformat(),
            'total': len(results),
            'successful': sum(1 for r in results if r.success),
            'results': [r.to_dict() for r in results]
        }
        Path(filepath).parent.mkdir(parents=True, exist_ok=True)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def _save_categorized_results(self, result_data: Dict, output_dir: Path):
        """å°†æ¢æµ‹ç»“æœæŒ‰ç±»åˆ«ä¿å­˜åˆ°ä¸åŒæ–‡ä»¶"""
        # æˆåŠŸçš„provider-modelç»„åˆ
        successful = {}
        # å¤±è´¥çš„ç»„åˆï¼ˆæŒ‰é”™è¯¯ç±»å‹åˆ†ç±»ï¼‰
        failed_by_auth = {}  # éœ€è¦è®¤è¯
        failed_by_model_not_found = {}  # æ¨¡å‹ä¸å­˜åœ¨
        failed_by_network = {}  # ç½‘ç»œ/è¿æ¥é—®é¢˜
        failed_by_empty_response = {}  # å“åº”ä¸ºç©º
        failed_by_other = {}  # å…¶ä»–é”™è¯¯
        
        for prov_name, prov_info in result_data['providers'].items():
            for model_name, model_info in prov_info['models'].items():
                if model_info['success']:
                    if prov_name not in successful:
                        successful[prov_name] = {'models': {}}
                    successful[prov_name]['models'][model_name] = model_info
                else:
                    error = model_info.get('error', '')
                    
                    # åˆ†ç±»é”™è¯¯
                    if '[api_key]' in error or '[cookie]' in error or '[token]' in error:
                        target = failed_by_auth
                    elif 'Model not found' in error:
                        target = failed_by_model_not_found
                    elif 'å“åº”ä¸ºç©º' in error:
                        target = failed_by_empty_response
                    elif 'timeout' in error.lower() or 'connection' in error.lower() or 'decode JSON' in error:
                        target = failed_by_network
                    else:
                        target = failed_by_other
                    
                    if prov_name not in target:
                        target[prov_name] = {'models': {}}
                    target[prov_name]['models'][model_name] = model_info
        
        # ä¿å­˜å„ä¸ªåˆ†ç±»
        categories = [
            ('successful', successful, 'æˆåŠŸ'),
            ('failed_auth_required', failed_by_auth, 'éœ€è¦è®¤è¯'),
            ('failed_model_not_found', failed_by_model_not_found, 'æ¨¡å‹ä¸å­˜åœ¨'),
            ('failed_empty_response', failed_by_empty_response, 'å“åº”ä¸ºç©º'),
            ('failed_network', failed_by_network, 'ç½‘ç»œ/è¿æ¥é—®é¢˜'),
            ('failed_other', failed_by_other, 'å…¶ä»–é”™è¯¯'),
        ]
        
        for filename, data, desc in categories:
            if data:  # åªä¿å­˜éç©ºçš„åˆ†ç±»
                filepath = output_dir / f"{filename}.json"
                summary = {
                    'category': desc,
                    'total_providers': len(data),
                    'total_combinations': sum(len(p['models']) for p in data.values()),
                    'providers': data
                }
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(summary, f, indent=2, ensure_ascii=False)
                print(f"  ğŸ“ {desc}: {filepath} ({summary['total_combinations']}ä¸ªç»„åˆ)")
        
        # ç”Ÿæˆæ¨¡å‹->providersæ˜ å°„æ–‡ä»¶
        if successful:
            from collections import defaultdict
            model_to_providers = defaultdict(list)
            
            for provider_name, prov_data in successful.items():
                for model_name in prov_data['models'].keys():
                    model_to_providers[model_name].append(provider_name)
            
            # æ’åºprovideråˆ—è¡¨
            model_to_providers = {k: sorted(v) for k, v in model_to_providers.items()}
            
            mapping_file = output_dir / "models_to_providers.json"
            mapping_data = {
                'generated_at': datetime.now().isoformat(),
                'total_models': len(model_to_providers),
                'models': model_to_providers
            }
            with open(mapping_file, 'w', encoding='utf-8') as f:
                json.dump(mapping_data, f, indent=2, ensure_ascii=False)
            print(f"  ğŸ—ºï¸  æ¨¡å‹æ˜ å°„: {mapping_file} ({len(model_to_providers)}ä¸ªæ¨¡å‹)")
    
    def probe_all_working_combinations(
        self,
        test_prompt: str = "Hello",
        timeout: int = 15,
        max_workers: int = 8,
        output_file: Optional[str] = None
    ) -> Dict[str, Dict[str, any]]:
        """æ¢æµ‹æ‰€æœ‰å¯ç”¨çš„providerå’Œmodelç»„åˆ
        
        Args:
            test_prompt: æµ‹è¯•æç¤ºè¯
            timeout: æ¯ä¸ªæµ‹è¯•çš„è¶…æ—¶æ—¶é—´(ç§’)
            max_workers: å¹¶å‘çº¿ç¨‹æ•°
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæä¾›åˆ™è‡ªåŠ¨ä¿å­˜
            
        Returns:
            æ ¼å¼: {
                'provider_name': {
                    'working': True/False,
                    'models': {
                        'model_name': {
                            'success': True/False,
                            'response_time': float,
                            'error': str (if failed)
                        }
                    }
                }
            }
        """
        try:
            from tqdm import tqdm
            use_tqdm = True
        except ImportError:
            use_tqdm = False
        
        providers = self.get_all_providers()
        # æ„å»ºæ‰€æœ‰provider-modelç»„åˆ
        tasks = []
        for p in providers:
            if p.working:
                # BlackboxProç‰¹æ®Šå¤„ç†ï¼šåªèƒ½ä½¿ç”¨ç©ºå­—ç¬¦ä¸²model
                if p.name == 'BlackboxPro':
                    tasks.append((p.name, ''))
                elif p.models:
                    # æœ‰æ˜ç¡®æ¨¡å‹åˆ—è¡¨çš„providerï¼Œè¿‡æ»¤ç©ºå­—ç¬¦ä¸²
                    valid_models = [m for m in p.models if m and isinstance(m, str)]
                    for model in valid_models:
                        tasks.append((p.name, model))
                else:
                    # æ²¡æœ‰æ¨¡å‹åˆ—è¡¨çš„providerï¼Œæµ‹è¯•é»˜è®¤æ¨¡å‹
                    tasks.append((p.name, None))
        
        results_map = {}
        
        def test_one(provider_name: str, model_name: Optional[str]) -> Tuple[str, Optional[str], bool, Optional[float], Optional[str]]:
            """æµ‹è¯•å•ä¸ªç»„åˆï¼Œè¿”å›(provider, model, success, time, error)"""
            success, resp, resp_time = self.test_provider(
                provider_name, 
                model_name, 
                test_prompt, 
                timeout, 
                verbose=False
            )
            error = None if success else resp
            return provider_name, model_name, success, resp_time, error
        
        # å¹¶å‘æµ‹è¯•
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {executor.submit(test_one, prov, mod): (prov, mod) for prov, mod in tasks}
            
            iterator = concurrent.futures.as_completed(futures)
            if use_tqdm:
                iterator = tqdm(iterator, total=len(futures), desc="æ¢æµ‹provider-modelç»„åˆ", unit="é¡¹")
            
            for future in iterator:
                provider_name, model_name, success, resp_time, error = future.result()
                
                # åˆå§‹åŒ–provideræ¡ç›®
                if provider_name not in results_map:
                    results_map[provider_name] = {
                        'working': False,
                        'models': {}
                    }
                
                # è®°å½•æ¨¡å‹Test result
                model_key = model_name if model_name else '__default__'
                results_map[provider_name]['models'][model_key] = {
                    'success': success,
                    'response_time': resp_time
                }
                if error:
                    results_map[provider_name]['models'][model_key]['error'] = error
                
                # å¦‚æœæœ‰ä»»ä½•ä¸€ä¸ªæ¨¡å‹æˆåŠŸï¼Œæ ‡è®°providerä¸ºworking
                if success:
                    results_map[provider_name]['working'] = True
        
        # æ„å»ºæœ€ç»ˆç»“æœ
        result_data = {
            'probe_time': datetime.now().isoformat(),
            'total_providers': len(results_map),
            'working_providers': sum(1 for p in results_map.values() if p['working']),
            'total_combinations': len(tasks),
            'successful_combinations': sum(
                1 for p in results_map.values() 
                for m in p['models'].values() 
                if m['success']
            ),
            'providers': results_map
        }
        
        # ä¿å­˜å®Œæ•´ç»“æœåˆ°æ–‡ä»¶
        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜å®Œæ•´ç»“æœ
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, indent=2, ensure_ascii=False)
            print(f"âœ… å®Œæ•´ç»“æœ: {output_path}")
            
            # æŒ‰æˆåŠŸ/å¤±è´¥/é”™è¯¯ç±»å‹åˆ†ç±»ä¿å­˜
            self._save_categorized_results(result_data, output_path.parent)
        
        return result_data
    
    def print_summary(self, include_real_test: bool = False):
        """æ‰“å°æ‘˜è¦"""
        providers = self.get_all_providers()
        working = [p for p in providers if p.working]
        recommended = self.get_recommended_providers(5)
        
        print(f"\n{'='*70}")
        print("G4FAdmin çŠ¶æ€æ‘˜è¦")
        print(f"{'='*70}")
        print(f"ğŸ“Š æ€»Provideræ•°: {len(providers)}")
        print(f"âœ… å¯ç”¨Provider: {len(working)}")
        print(f"âŒ ä¸å¯ç”¨Provider: {len(providers) - len(working)}")
        
        if recommended:
            print(f"\nğŸ¯ æ¨èProvider (å‰5):")
            for i, p in enumerate(recommended, 1):
                features = []
                if p.supports_stream:
                    features.append("æµå¼")
                if p.supports_message_history:
                    features.append("å†å²")
                if p.models:
                    features.append(f"{len(p.models)}æ¨¡å‹")
                feat_str = ", ".join(features) or "åŸºç¡€"
                print(f"  {i}. {p.name:25s} [{feat_str}]")
        
        if include_real_test and recommended:
            print(f"\nğŸ§ª çœŸå®æµ‹è¯• (å‰3ä¸ªæ¨è):")
            for i, p in enumerate(recommended[:3], 1):
                success, resp, t = self.test_provider(p.name, test_prompt="1+1=?", timeout=15)
                status = "âœ…" if success else "âŒ"
                time_str = f"{t:.2f}s" if t else "N/A"
                result = (resp[:50] if resp else "")
                print(f"  {i}. {status} {p.name:25s} [{time_str}] {result}")
        
        models = self.get_all_models()
        if models:
            print(f"\nğŸ“¦ æ€»Modelæ•°: {len(models)}")
            print("\nğŸ”¥ çƒ­é—¨Model (å‰10):")
            sorted_models = sorted(models, key=lambda m: len(m.providers), reverse=True)
            for i, m in enumerate(sorted_models[:10], 1):
                print(f"  {i}. {m.name:30s} ({len(m.providers)} providers)")
        
        print(f"\n{'='*70}\n")
    
    def _chat_internal(
        self,
        messages: List[Dict[str, str]],
        provider: Optional[str],
        model: Optional[str],
        auto_select: bool,
        timeout: int
    ) -> Tuple[bool, str, Optional[str], Optional[str]]:
        """å†…éƒ¨èŠå¤©å®ç°ï¼ˆéæµå¼ï¼‰"""
        # è·å–å€™é€‰ç»„åˆ
        candidates = self._get_chat_candidates(provider, model)
        
        if not candidates:
            # ç»™å‡ºæ›´æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯
            if model is not None:
                error_msg = f"æ‰¾ä¸åˆ°æ”¯æŒæ¨¡å‹ '{model}' çš„å¯ç”¨providerã€‚è¯·ä½¿ç”¨ 'g4fadmin --find {model}' æŸ¥æ‰¾æ”¯æŒè¯¥æ¨¡å‹çš„providersï¼Œæˆ–ä½¿ç”¨ 'g4fadmin --list-models' æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹ã€‚"
            else:
                error_msg = "æ²¡æœ‰å¯ç”¨çš„provider"
            return False, error_msg, None, None
        
        # å°è¯•å€™é€‰ç»„åˆ
        last_error = ""
        for i, candidate in enumerate(candidates):
            try:
                prov_name = candidate['provider']
                model_name = candidate['model']
                
                if not hasattr(self.g4f.Provider, prov_name):
                    continue
                
                provider_class = getattr(self.g4f.Provider, prov_name)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è®¤è¯
                if hasattr(provider_class, 'needs_auth') and provider_class.needs_auth:
                    last_error = f"{prov_name} éœ€è¦è®¤è¯ã€‚è¯·ä½¿ç”¨ 'g4fadmin --cookie-providers' æŸ¥çœ‹é…ç½®æ–¹æ³•ï¼Œæˆ–é€‰æ‹©å…¶ä»–æ¨¡å‹ã€‚"
                    logger.debug(f"Provider {prov_name} éœ€è¦è®¤è¯ï¼Œè·³è¿‡")
                    if not auto_select or i >= len(candidates) - 1:
                        return False, last_error, prov_name, model_name
                    continue
                
                # BlackboxProç‰¹æ®Šå¤„ç†
                if prov_name == 'BlackboxPro':
                    model_name = ''
                
                # å¦‚æœæ²¡æœ‰æŒ‡å®šmodelï¼Œè‡ªåŠ¨é€‰æ‹©
                if model_name is None:
                    model_name = self._auto_select_model(provider_class)
                
                # è°ƒç”¨g4fï¼ˆéæµå¼ï¼‰
                response = self.g4f.ChatCompletion.create(
                    model=model_name,
                    messages=messages,
                    provider=provider_class,
                    timeout=timeout,
                    stream=False
                )
                
                # å¤„ç†å“åº”
                if hasattr(response, '__iter__') and not isinstance(response, (str, dict)):
                    chunks = list(response)
                    response = chunks[-1] if chunks and isinstance(chunks[-1], dict) else ''.join(str(c) for c in chunks if str(c).strip() and str(c) != '{}')
                
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•ä¿®å¤JSON
                if isinstance(response, str):
                    try:
                        from json_repair import repair_json
                        response = json.loads(repair_json(response))
                    except:
                        pass
                
                result = self._extract_text_from_response(response)
                
                if not result:
                    last_error = "å“åº”ä¸ºç©º"
                    if not auto_select or i >= len(candidates) - 1:
                        return False, last_error, prov_name, model_name
                    continue
                
                return True, result, prov_name, model_name
                
            except Exception as e:
                last_error = str(e)
                logger.debug(f"Provider {candidate['provider']} å¤±è´¥: {last_error}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯è®¤è¯é”™è¯¯
                if 'auth' in last_error.lower() or 'cookie' in last_error.lower() or 'MissingAuthError' in last_error:
                    last_error = f"{candidate['provider']} éœ€è¦è®¤è¯ã€‚è¯·ä½¿ç”¨ 'g4fadmin --cookie-providers' æŸ¥çœ‹é…ç½®æ–¹æ³•ï¼Œæˆ–é€‰æ‹©å…¶ä»–æ¨¡å‹ã€‚"
                
                if not auto_select or i >= len(candidates) - 1:
                    return False, last_error, candidate['provider'], candidate.get('model')
                
                continue
        
        return False, last_error, None, None
    
    def _chat_stream(
        self,
        messages: List[Dict[str, str]],
        provider: Optional[str],
        model: Optional[str],
        auto_select: bool,
        timeout: int
    ):
        """å†…éƒ¨èŠå¤©å®ç°ï¼ˆæµå¼ï¼‰- ç”Ÿæˆå™¨"""
        # è·å–å€™é€‰ç»„åˆ
        candidates = self._get_chat_candidates(provider, model)
        
        if not candidates:
            # ç»™å‡ºæ›´æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯
            if model is not None:
                error_msg = f"æ‰¾ä¸åˆ°æ”¯æŒæ¨¡å‹ '{model}' çš„å¯ç”¨providerã€‚è¯·ä½¿ç”¨ 'g4fadmin --find {model}' æŸ¥æ‰¾æ”¯æŒè¯¥æ¨¡å‹çš„providersï¼Œæˆ–ä½¿ç”¨ 'g4fadmin --list-models' æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹ã€‚"
            else:
                error_msg = "æ²¡æœ‰å¯ç”¨çš„provider"
            yield ("error", error_msg, None, None)
            return
        
        # å°è¯•å€™é€‰ç»„åˆ
        last_error = ""
        for i, candidate in enumerate(candidates):
            try:
                prov_name = candidate['provider']
                model_name = candidate['model']
                
                if not hasattr(self.g4f.Provider, prov_name):
                    continue
                
                provider_class = getattr(self.g4f.Provider, prov_name)
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è®¤è¯
                if hasattr(provider_class, 'needs_auth') and provider_class.needs_auth:
                    last_error = f"{prov_name} éœ€è¦è®¤è¯ã€‚è¯·ä½¿ç”¨ 'g4fadmin --cookie-providers' æŸ¥çœ‹é…ç½®æ–¹æ³•ï¼Œæˆ–é€‰æ‹©å…¶ä»–æ¨¡å‹ã€‚"
                    logger.debug(f"Provider {prov_name} éœ€è¦è®¤è¯ï¼Œè·³è¿‡")
                    if not auto_select or i >= len(candidates) - 1:
                        yield ("error", last_error, prov_name, model_name)
                        return
                    continue
                
                # BlackboxProç‰¹æ®Šå¤„ç†
                if prov_name == 'BlackboxPro':
                    model_name = ''
                
                # å¦‚æœæ²¡æœ‰æŒ‡å®šmodelï¼Œè‡ªåŠ¨é€‰æ‹©
                if model_name is None:
                    model_name = self._auto_select_model(provider_class)
                
                # è°ƒç”¨g4fï¼ˆæµå¼ï¼‰
                response = self.g4f.ChatCompletion.create(
                    model=model_name,
                    messages=messages,
                    provider=provider_class,
                    timeout=timeout,
                    stream=True
                )
                
                # yield chunks - æå–æ–‡æœ¬å†…å®¹
                for chunk in response:
                    if not chunk:
                        continue
                    
                    # æµå¼chunkæ˜¯ç‰¹æ®Šæ ¼å¼: {'choices': [{'delta': {'content': '...'}}]}
                    text = None
                    if isinstance(chunk, dict):
                        # æå– delta.content
                        if 'choices' in chunk and chunk['choices']:
                            delta = chunk['choices'][0].get('delta', {})
                            text = delta.get('content', '')
                    elif isinstance(chunk, str):
                        text = chunk
                    # å…¶ä»–ç±»å‹ç›´æ¥è·³è¿‡ï¼Œä¸è¦è½¬str
                    
                    # åªyieldéç©ºæ–‡æœ¬å†…å®¹
                    if text:
                        yield text
                
                # æˆåŠŸå®Œæˆ
                yield ("success", prov_name, model_name)
                return
                
            except Exception as e:
                last_error = str(e)
                logger.debug(f"Provider {candidate['provider']} å¤±è´¥: {last_error}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯è®¤è¯é”™è¯¯
                if 'auth' in last_error.lower() or 'cookie' in last_error.lower() or 'MissingAuthError' in last_error:
                    last_error = f"{candidate['provider']} éœ€è¦è®¤è¯ã€‚è¯·ä½¿ç”¨ 'g4fadmin --cookie-providers' æŸ¥çœ‹é…ç½®æ–¹æ³•ï¼Œæˆ–é€‰æ‹©å…¶ä»–æ¨¡å‹ã€‚"
                
                if not auto_select or i >= len(candidates) - 1:
                    yield ("error", last_error, candidate['provider'], candidate.get('model'))
                    return
                
                continue
        
        # æ‰€æœ‰å€™é€‰éƒ½å¤±è´¥
        yield ("error", last_error, None, None)
    
    def _get_chat_candidates(self, provider: Optional[str], model: Optional[str]) -> List[Dict]:
        """è·å–èŠå¤©å€™é€‰ç»„åˆ"""
        # å¦‚æœæŒ‡å®šäº†provider
        if provider is not None:
            # ç›´æ¥ä½¿ç”¨æŒ‡å®šçš„providerå’Œmodel
            return [{'provider': provider, 'model': model, 'time': 0}]
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šproviderä½†æŒ‡å®šäº†modelï¼Œåœ¨successful.jsonä¸­æŸ¥æ‰¾æ”¯æŒè¯¥modelçš„provider
        if model is not None:
            output_dir = Path("output")
            successful_file = output_dir / "successful.json"
            
            candidates = []
            if successful_file.exists():
                try:
                    with open(successful_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # æŸ¥æ‰¾æ”¯æŒè¯¥modelçš„providersï¼ŒæŒ‰å“åº”æ—¶é—´æ’åº
                    for prov_name, prov_data in data.get('providers', {}).items():
                        if model in prov_data.get('models', {}):
                            model_info = prov_data['models'][model]
                            if model_info.get('success'):
                                candidates.append({
                                    'provider': prov_name,
                                    'model': model,
                                    'time': model_info.get('response_time', 999)
                                })
                    
                    if candidates:
                        candidates.sort(key=lambda x: x['time'])
                        return candidates
                except Exception as e:
                    logger.warning(f"æ— æ³•è¯»å–successful.json: {e}")
            
            # å¦‚æœåœ¨successful.jsonä¸­æ‰¾ä¸åˆ°ï¼Œå°è¯•ä»æ‰€æœ‰providerä¸­æŸ¥æ‰¾
            # è¿™åŒ…æ‹¬å¯èƒ½éœ€è¦è®¤è¯ä½†ç”¨æˆ·å¯èƒ½å·²é…ç½®çš„provider
            logger.info(f"åœ¨successful.jsonä¸­æœªæ‰¾åˆ°æ¨¡å‹ {model}ï¼Œå°è¯•ä»æ‰€æœ‰providersæŸ¥æ‰¾...")
            
            # æŸ¥æ‰¾æ‰€æœ‰å£°ç§°æ”¯æŒè¯¥æ¨¡å‹çš„provider
            potential_providers = []
            for provider_name in dir(self.g4f.Provider):
                if provider_name.startswith('_'):
                    continue
                
                try:
                    provider_class = getattr(self.g4f.Provider, provider_name)
                    if not hasattr(provider_class, '__mro__'):
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰modelså±æ€§
                    if hasattr(provider_class, 'models'):
                        models = provider_class.models
                        if isinstance(models, list) and model in models:
                            potential_providers.append({
                                'provider': provider_name,
                                'model': model,
                                'time': 999
                            })
                except:
                    continue
            
            if potential_providers:
                logger.info(f"æ‰¾åˆ° {len(potential_providers)} ä¸ªå£°ç§°æ”¯æŒ {model} çš„providersï¼Œå°†å°è¯•ä½¿ç”¨")
                return potential_providers
            
            # å®Œå…¨æ‰¾ä¸åˆ°æ”¯æŒè¯¥æ¨¡å‹çš„providerï¼Œè¿”å›ç©ºåˆ—è¡¨
            # è¿™ä¼šå¯¼è‡´é”™è¯¯æç¤ºè€Œä¸æ˜¯å›é€€åˆ°å…¶ä»–æ¨¡å‹
            logger.warning(f"æ‰¾ä¸åˆ°ä»»ä½•æ”¯æŒæ¨¡å‹ {model} çš„provider")
            return []
        
        # æ—¢æ²¡æœ‰æŒ‡å®šproviderä¹Ÿæ²¡æœ‰æŒ‡å®šmodelï¼Œè‡ªåŠ¨é€‰æ‹©
        # ä¼˜å…ˆä½¿ç”¨successful.jsonä¸­çš„ç»„åˆ
        output_dir = Path("output")
        successful_file = output_dir / "successful.json"
        
        candidates = []
        if successful_file.exists():
            try:
                with open(successful_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # æå–æ‰€æœ‰æˆåŠŸçš„provider-modelç»„åˆï¼ŒæŒ‰å“åº”æ—¶é—´æ’åº
                for prov_name, prov_data in data.get('providers', {}).items():
                    for model_name, model_info in prov_data.get('models', {}).items():
                        if model_info.get('success'):
                            candidates.append({
                                'provider': prov_name,
                                'model': model_name,
                                'time': model_info.get('response_time', 999)
                            })
                
                candidates.sort(key=lambda x: x['time'])
            except Exception as e:
                logger.warning(f"æ— æ³•è¯»å–successful.json: {e}")
        
        # å¦‚æœæ²¡æœ‰successful.jsonï¼Œä½¿ç”¨æ¨èprovider
        if not candidates:
            recommended = self.get_recommended_providers(5)
            for p in recommended:
                if p.models:
                    candidates.append({
                        'provider': p.name,
                        'model': p.models[0],
                        'time': 999
                    })
                else:
                    candidates.append({
                        'provider': p.name,
                        'model': None,
                        'time': 999
                    })
        
        return candidates
    
    def _auto_select_model(self, provider_class) -> str:
        """è‡ªåŠ¨é€‰æ‹©æ¨¡å‹"""
        if hasattr(provider_class, 'default_model'):
            return provider_class.default_model
        elif hasattr(provider_class, 'models') and provider_class.models:
            models_list = provider_class.models
            if isinstance(models_list, list):
                valid = [m for m in models_list if m]
                return valid[0] if valid else 'auto'
            else:
                return 'auto'
        else:
            return 'auto'
    
    def chat(
        self,
        message: str,
        provider: Optional[str] = None,
        model: Optional[str] = None,
        stream: bool = False,
        history: Optional[List[Dict[str, str]]] = None,
        auto_select: bool = True,
        timeout: int = 30
    ):
        """èŠå¤©æ¥å£ï¼Œå°è£…g4fçš„ChatCompletion
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            provider: æŒ‡å®šprovideråç§°ï¼ŒNoneåˆ™è‡ªåŠ¨é€‰æ‹©
            model: æŒ‡å®šæ¨¡å‹åç§°ï¼ŒNoneåˆ™ä½¿ç”¨provideré»˜è®¤
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
            history: æ¶ˆæ¯å†å² [{"role": "user", "content": "..."}, ...]
            auto_select: å¦‚æœæŒ‡å®šçš„ç»„åˆå¤±è´¥ï¼Œæ˜¯å¦è‡ªåŠ¨å°è¯•å…¶ä»–ç»„åˆ
            timeout: è¶…æ—¶æ—¶é—´(ç§’)
            
        Returns:
            stream=False: (success, response, used_provider, used_model)
            stream=True: generator yielding chunks (æœ€åyieldå…ƒç»„ä¿¡æ¯)
        """
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = history.copy() if history else []
        messages.append({"role": "user", "content": message})
        
        if stream:
            return self._chat_stream(messages, provider, model, auto_select, timeout)
        else:
            return self._chat_internal(messages, provider, model, auto_select, timeout)

